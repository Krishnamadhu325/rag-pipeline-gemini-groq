{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNASYtA4+D8kUlDsGXTcIPI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install -q langchain langchain-groq"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8REsLSCO7fGP","executionInfo":{"status":"ok","timestamp":1768367792177,"user_tz":-330,"elapsed":5470,"user":{"displayName":"Krishna KM","userId":"02430422518122230976"}},"outputId":"7c5c5d38-7f68-4030-f23b-aeda905f4209"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/137.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"vdK3S4QLr164","executionInfo":{"status":"ok","timestamp":1768367800114,"user_tz":-330,"elapsed":1589,"user":{"displayName":"Krishna KM","userId":"02430422518122230976"}}},"outputs":[],"source":["from google.colab import userdata\n","GROQ_API_KEY=userdata.get('GROQ_API_KEY')"]},{"cell_type":"code","source":["from langchain_groq import ChatGroq"],"metadata":{"id":"eNfMupEuthZv","executionInfo":{"status":"ok","timestamp":1768367828521,"user_tz":-330,"elapsed":7,"user":{"displayName":"Krishna KM","userId":"02430422518122230976"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["llm = ChatGroq(model='openai/gpt-oss-20b',groq_api_key=GROQ_API_KEY)"],"metadata":{"id":"qXgmFvsH76xJ","executionInfo":{"status":"ok","timestamp":1768367873478,"user_tz":-330,"elapsed":1752,"user":{"displayName":"Krishna KM","userId":"02430422518122230976"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["res = llm.invoke(\"Give me the list of popular LLMs and their company names?\")\n","print(res.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3No9C-iS8FVC","executionInfo":{"status":"ok","timestamp":1768368034615,"user_tz":-330,"elapsed":3357,"user":{"displayName":"Krishna KM","userId":"02430422518122230976"}},"outputId":"1041f593-1c42-440f-a081-4f76a8a30480"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["**Popular Large Language Models (LLMs) – Company & Key Details (as of 2026)**  \n","\n","| LLM (Version) | Company | Release Year | Model Size (approx.) | Notable Capabilities / Tier |\n","|---------------|---------|--------------|----------------------|-----------------------------|\n","| **GPT‑4** | OpenAI | 2023 | 2.9 trillion parameters | General‑purpose, high‑accuracy text generation |\n","| **GPT‑4 Turbo** | OpenAI | 2024 | 2.9 trillion (optimized) | Faster, cheaper inference, same quality as GPT‑4 |\n","| **GPT‑4o** | OpenAI | 2024 | 1.3 trillion | “Omni” model with multimodal (text+image) support |\n","| **GPT‑4o mini** | OpenAI | 2025 | 0.1 trillion | Lightweight, cost‑effective, still high‑quality |\n","| **GPT‑3.5** | OpenAI | 2022 | 1.3 trillion | Widely used in 2023‑24 for many apps |\n","| **GPT‑3** | OpenAI | 2020 | 175 B | The first large‑scale public LLM |\n","| **Claude 3** | Anthropic | 2024 | 2.9 trillion | “Opus” tier (full‑size), “Sonnet” (mid‑size), “Haiku” (compact) |\n","| **Claude 2.1** | Anthropic | 2023 | 1.3 trillion | Improved safety & efficiency over Claude 2 |\n","| **Claude 2** | Anthropic | 2022 | 1.3 trillion | Original Claude release |\n","| **Gemini Pro** | Google DeepMind | 2024 | 1.3 trillion | Text‑only, high‑accuracy, cost‑efficient |\n","| **Gemini Pro Vision** | Google DeepMind | 2024 | 1.3 trillion | Adds image‑to‑text understanding |\n","| **Gemini Ultra** | Google DeepMind | 2025 | 2.9 trillion | Highest‑end tier with advanced multimodal reasoning |\n","| **PaLM 2** | Google | 2023 | 540 B | General‑purpose, large‑scale text model |\n","| **PaLM 2 Vision** | Google | 2024 | 540 B | Adds image‑to‑text capabilities |\n","| **LLaMA 2** | Meta (Meta Platforms) | 2023 | 13 B / 70 B | Open‑source family, widely adopted in research & industry |\n","| **LLaMA 3** | Meta | 2025 | 13 B / 70 B | Next‑gen, improved safety & multimodal support |\n","| **Mistral 7B** | Mistral AI | 2023 | 7 B | Fast, low‑cost, high‑quality for many use‑cases |\n","| **Mistral 12B** | Mistral AI | 2024 | 12 B | Larger variant with better reasoning |\n","| **Mixtral 8×7B** | Mistral AI | 2024 | 56 B (8×7B) | Combines 8 independent 7B models for higher capacity |\n","| **OpenChat** | OpenChat (OpenAI‑style) | 2024 | 7 B | Open‑source alternative, community‑maintained |\n","| **Dolly‑2** | Databricks | 2023 | 7 B | Open‑source LLM trained on public data |\n","| **StableLM** | Stability AI | 2024 | 7 B / 13 B | Open‑source, multi‑modal, safe‑by‑design |\n","\n","### Quick Reference Highlights\n","\n","| Model | Company | Tier | Approx. Size | Release Year | Why it’s Popular |\n","|-------|---------|------|--------------|--------------|------------------|\n","| GPT‑4 Turbo | OpenAI | General | 2.9 T | 2024 | Fast, cheap, same quality as GPT‑4 |\n","| Claude 3 (Opus) | Anthropic | Premium | 2.9 T | 2024 | Strong safety, versatile |\n","| Gemini Ultra | Google DeepMind | Premium | 2.9 T | 2025 | Leading multimodal performance |\n","| LLaMA 2 70B | Meta | Open‑source | 70 B | 2023 | Widely used for research & commercial tweaks |\n","| Mistral 12B | Mistral AI | Mid | 12 B | 2024 | Best performance‑per‑cost ratio |\n","| Mixtral 8×7B | Mistral AI | High | 56 B | 2024 | Combines 8 small models for large capacity |\n","\n","> **Tip:** If you’re building a product that requires high safety and fine‑tuned control, Claude 3 or Gemini Ultra are top choices. For research or open‑source experimentation, LLaMA 2/3 and Mistral/Mixtral are excellent starting points.  \n","\n","Feel free to let me know if you need deeper dive into any particular model, pricing, or integration tips!\n"]}]},{"cell_type":"code","source":["res = llm.invoke(\"Give me today's date\")\n","print(res.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jVMEjYrk8sRK","executionInfo":{"status":"ok","timestamp":1768368159019,"user_tz":-330,"elapsed":238,"user":{"displayName":"Krishna KM","userId":"02430422518122230976"}},"outputId":"9af662f8-32aa-4ce7-825c-c52d24981bc9"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["The current date is **2026‑01‑14**.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"dPr767Yt9LXC"},"execution_count":null,"outputs":[]}]}