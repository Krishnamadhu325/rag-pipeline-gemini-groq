# Generative AI – RAG Pipeline Implementation

This repository contains guided implementations of Retrieval-Augmented Generation (RAG) concepts completed during a Microsoft Generative AI training program.

## Overview
The notebooks demonstrate how to build and experiment with LLM-based applications and RAG workflows using document embeddings and vector databases to answer queries based on external documents.

## Notebooks
All Colab notebooks from Day 1 through Day 5 are included:

- **Day 1:** Fundamentals of LLMs and Generative AI  
- **Day 2:** Chatbots using Gemini & Groq APIs  
- **Day 3:** Retrieval concepts and NotebookLM  
- **Day 4:** Text preprocessing, chunking, and vector database setup  
- **Day 5:** End-to-end RAG pipeline with embeddings and query retrieval

## Project Highlights
- Document embedding using **Google Gemini Embeddings**
- Vector storage using **ChromaDB**
- Semantic retrieval with similarity-based retrievers
- Context-aware generation using **Groq LLM**
- Source document attribution for responses

## Sample Documents
The `sample_documents/` folder contains example PDFs used to demonstrate RAG workflows.

## Technologies Used
Python · Google Colab · LangChain utils · Gemini Embeddings · ChromaDB · Groq LLM

## Notes
This project was developed as part of a **guided training program** to gain hands-on experience with modern Generative AI pipelines.
