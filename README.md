# Generative AI – RAG Pipeline Implementation

This repository contains a guided implementation of a Retrieval-Augmented Generation (RAG) pipeline
completed during a Microsoft Generative AI training program.

## Overview
The project demonstrates how to answer user queries using external documents by combining
vector databases and large language models.

## Key Features
- Document embedding using Google Gemini Embeddings
- Vector storage using ChromaDB
- Semantic retrieval based on similarity search
- Context-aware answer generation using Groq LLM
- Source-aware responses for improved reliability

## Technologies Used
- Python
- LangChain
- Google Gemini Embeddings
- ChromaDB
- Groq LLM
- Google Colab

## Sample Documents
- `sample_documents/` – Example PDFs used for demonstrating document-based question answering in the RAG pipeline

## Note
This project was developed as a guided hands-on exercise during training to gain practical
experience with modern Generative AI pipelines.
